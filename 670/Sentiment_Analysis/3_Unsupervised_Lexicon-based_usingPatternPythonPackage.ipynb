{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern: A Python package for unsupervised (lexicon-based) sentiment analysis\n",
    "\n",
    "More advanced than simplying counting the number of positive and negative words and determining the overall sentiment (or opinion)\n",
    "\n",
    "Written text can be broadly categorized into two types: facts and opinions. Opinions carry people's sentiments, appraisals and feelings toward the world. The pattern.en module bundles a lexicon of adjectives (e.g., good, bad, amazing, irritating, ...) that occur frequently in product reviews, annotated with scores for sentiment polarity (positive ↔ negative) and subjectivity (objective ↔ subjective). \n",
    "\n",
    "The sentiment() function returns a (polarity, subjectivity)-tuple for the given sentence, based on the adjectives it contains, where polarity is a value between -1.0 and +1.0 and subjectivity between 0.0 and 1.0. The sentence can be a string, Text, Sentence, Chunk, Word or a Synset (see below). \n",
    "\n",
    "The positive() function returns True if the given sentence's polarity is above the threshold. The threshold can be lowered or raised, but overall +0.1 gives the best results for product reviews. Accuracy is about 75% for movie reviews.\n",
    "\n",
    "Source: http://www.clips.ua.ac.be/pages/pattern-en#sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The simplest way to install Pattern is using pip:\n",
    "**pip install pattern**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pattern.en import sentiment\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment('iPhone 5 is best smartphone in the world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment('dirty place and poor service')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    \"The server was rude, bad location, poor service overall\",\n",
    "    \"This bike is amazing, but the brake is very poor\",\n",
    "    \"This ice maker works great, the price is very reasonable, some bad smell from the ice maker\",\n",
    "    \"The food was awesome, but the water was very rude\"\n",
    "    ]\n",
    "\n",
    "for row in reviews:\n",
    "    print sentiment(row)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images\\pattern.gif\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    \"The server was rude, bad location, poor service overall\",\n",
    "    \"This bike is amazing, but the brake is very poor\",\n",
    "    \"This ice maker works great, the price is very reasonable, some bad smell from the ice maker\",\n",
    "    \"The food was awesome, but the water was very rude\"\n",
    "    ]\n",
    "\n",
    "for row in reviews:\n",
    "    score = sentiment(row)\n",
    "    print score[0], score[1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    \"The server was rude, bad location, poor service overall\",\n",
    "    \"This bike is amazing, but the brake is very poor\",\n",
    "    \"This ice maker works great, the price is very reasonable, some bad smell from the ice maker\",\n",
    "    \"The food was awesome, but the water was very rude\"\n",
    "    ]\n",
    "\n",
    "# Remove useless numbers and alphanumerical words\n",
    "documents = [re.sub(\"[^a-zA-Z]+\", \" \", document) for document in reviews]\n",
    "# tokenize\n",
    "texts = [[word for word in document.lower().split() ] for document in documents]\n",
    "# remove common words \n",
    "stoplist = stopwords.words('english')\n",
    "texts = [[word for word in text if word not in stoplist] for text in texts]\n",
    "#remove short words\n",
    "texts = [[ word for word in tokens if len(word) >= 3 ] for tokens in texts]\n",
    "\n",
    "for row in texts:\n",
    "    score = sentiment(row)\n",
    "    print score[0], score[1]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Actual Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "openfile = open('data/sample_tweet_from_azuredatafactory.csv', 'rb')\n",
    "r = csv.reader(openfile)\n",
    "for i in r:\n",
    "    reviews.append(i)  \n",
    "openfile.close()\n",
    "reviews[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without text preprocessing ... this is good enough \n",
    "for row in reviews:\n",
    "    tweet = row[0]\n",
    "    score = sentiment(tweet)\n",
    "    print score[0], score[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove extra brackets\n",
    "reviews = [x for y in reviews for x in y]\n",
    "# Remove useless numbers and alphanumerical words\n",
    "documents = [re.sub(\"[^a-zA-Z]+\", \" \", document) for document in reviews]\n",
    "# tokenize\n",
    "texts = [[word for word in document.lower().split() ] for document in documents]\n",
    "# remove common words \n",
    "stoplist = stopwords.words('english')\n",
    "texts = [[word for word in text if word not in stoplist] for text in texts]\n",
    "#remove short words\n",
    "texts = [[ word for word in tokens if len(word) >= 3 ] for tokens in texts]\n",
    "\n",
    "for row in texts:\n",
    "    data = row[0]\n",
    "    score = sentiment(data)\n",
    "    print score[0], score[1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#saving results in csv\n",
    "\n",
    "reviews = []\n",
    "openfile = open('data/sample_tweet_from_azuredatafactory.csv', 'rb')\n",
    "r = csv.reader(openfile)\n",
    "for i in r:\n",
    "    reviews.append(i)  \n",
    "openfile.close()\n",
    "\n",
    "writefile = open('data/output_sentiscore_tweets.csv', 'wb')\n",
    "w = csv.writer(writefile)\n",
    "for row in reviews:\n",
    "    tweet = row[0]\n",
    "    score = sentiment(tweet)\n",
    "    w.writerow([score[0], score[1]])     \n",
    "writefile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#saving results in csv - another approach\n",
    "\n",
    "reviews = []\n",
    "openfile = open('data\\\\sample_tweet_from_azuredatafactory.csv', 'rb')\n",
    "r = csv.reader(openfile)\n",
    "for i in r:\n",
    "    reviews.append(i)  \n",
    "openfile.close()\n",
    "\n",
    "score=[]\n",
    "for row in reviews:\n",
    "    score.append(sentiment(row[0]))\n",
    "\n",
    "output=zip(score)\n",
    "writer = csv.writer(open('data\\\\output_sentiscore3.csv', 'wb'))\n",
    "writer.writerows(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in score:\n",
    "    print item[0], \",\", item[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating Positive Tweets and Negative Tweets & Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_review = []\n",
    "negative_review = []\n",
    "neutral_review = []\n",
    "\n",
    "for row in reviews:\n",
    "    tweet = row[0]\n",
    "    score = sentiment(tweet)\n",
    "    if score[0] > 0:\n",
    "        positive_review.append(tweet)\n",
    "    elif score[0] == 0:\n",
    "        neutral_review.append(tweet)\n",
    "    else:\n",
    "        negative_review.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(positive_review)\n",
    "print len(negative_review)\n",
    "print len(neutral_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Frequency of Positive Reivews Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove all urls\n",
    "documents = [re.sub(r\"http\\S+\", '', document) for document in positive_review] \n",
    "# Remove useless numbers and alphanumerical words\n",
    "documents = [re.sub(\"[^a-zA-Z]+\", \" \", document) for document in documents]\n",
    "# tokenize\n",
    "texts = [document.lower().split() for document in documents]\n",
    "# remove common words \n",
    "stoplist = stopwords.words('english')\n",
    "texts = [[word for word in text if word not in stoplist] for text in texts]\n",
    "#remove short words\n",
    "texts = [[ word for word in tokens if len(word) >= 3 ] for tokens in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove extra brackets)\n",
    "cleaned_positive_review_tokens = [x for y in texts for x in y]\n",
    "cleaned_positive_review_tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word frequency\n",
    "from collections import Counter\n",
    "\n",
    "positive_review_wordcounts= Counter(cleaned_positive_review_tokens)\n",
    "positive_review_wordcounts.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save the word frequency in dataframe (Excel like)\n",
    "positivereview_wordfreq = pd.DataFrame(positive_review_wordcounts.most_common())\n",
    "positivereview_wordfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This process could be very slow for a large corpus\n",
    "\n",
    "from os import path\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "text = str(cleaned_positive_review_tokens)\n",
    "\n",
    "# Generate a word cloud image\n",
    "wc = WordCloud(background_color=\"white\", max_words=2000).generate(text)\n",
    "wc.generate(text)\n",
    "\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "plt.imshow(wc)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# take relative word frequencies into account, lower max_font_size\n",
    "#wordcloud = WordCloud(max_font_size=40, relative_scaling=.5).generate(text)\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(wc)\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"data/pos.png\")\n",
    "plt.savefig(\"data/pos.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Now, you can perform the same analysis for negative reviews\n",
    "- First, perform the word frequency analysis on the negative reviews\n",
    "- Then, combine the results of positive and negative reviews for comparison\n",
    "- Also, you can compare the word clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
