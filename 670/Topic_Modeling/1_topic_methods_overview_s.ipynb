{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic modeling is a technique to extract hidden **themes** or **topics** from unstructured data (texts). **unsupervised document clustering**\n",
    "\n",
    "- a topic (hospital) may be a collection of words such as hospital, doctor, medicine, cure, and patient.\n",
    "- used for recommendation systems (e.g., New York Times, Job search engines)\n",
    "- used to organize customer reviews, social media posts, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A topic is a **probality distribution over different words or tokens**. These words often co-appear in the same documents or articles (e.g., health, doctor, patient, medicine)\n",
    "\n",
    "> For example, if you were to create three topics from restaurant reviews, you would have the following topics (**Mexican**, **Food Taste**, and **Japanese**) and words with **different probability distribution**.\n",
    "\n",
    "> A customer review (**\"The burrito was terrible. I never try that again. Instead, Sushi was great! I love soy source and Gyoza\"** may contains three topics: ** Mexican (40%)**, **Food Taste (20%)**, and **Japanese (40%)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another example. If you were to find topics from a journal article, you would have the following topics and words with different probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"http://journalofdigitalhumanities.org/wp-content/uploads/2013/02/blei_lda_illustration.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation = LDA\n",
    "\n",
    "There are different algorithms used for topic modeling. **Latent Dirichlet allocation (LDA)** is considered the most popular algorithm for topic modeling. LDA automatically discovers hidden topics from texts. \n",
    "\n",
    "<img src= \"images/lda.png\">\n",
    "\n",
    "> * For each document in a corpus (box D):\n",
    "    - Determine the a topic mixture (**θ**) or the topic proportion \n",
    "    - For each word in the document (box N):\n",
    "        * Assign a topic (**Z**) from the topic mixture (**θ**)\n",
    "        * Choose the word from the distribution of words (**β**) of the topic (box K)\n",
    "        \n",
    "> **α** represents the dirichlet parameter on the per-document topic; **η** represents dirichlet parameter on the per-topic word; **dirichlet** = **multinominal distribution**\n",
    "\n",
    "\n",
    "**I strongly recommend the following articles and video for more information about LDA**. \n",
    "\n",
    " - An introduction of topic modeling to a layman https://www.quora.com/What-is-the-best-way-to-explain-topic-modeling-to-a-layman\n",
    " - Beginners Guide to Topic Modeling in Python https://www.analyticsvidhya.com/blog/2016/08/beginners-guide-to-topic-modeling-in-python/\n",
    " - \"Probabilistic Topic Models\" By David M. Blei, Communications of the ACM, Vol. 55 No. 4, Pages 77-84. You can download this article from our course website\n",
    " - https://www.youtube.com/watch?v=3mHy4OSyRf0 (A YouTube video explaining how LDA works)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "\n",
    "- http://www.kdnuggets.com/2016/07/americas-next-topic-model.html\n",
    "- http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/\n",
    "- https://www.analyticsvidhya.com/blog/2016/08/beginners-guide-to-topic-modeling-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools\n",
    "\n",
    "- Gensim: a Python package for topic modeling\n",
    "- R & topicmodels (R package for topic modeliing)\n",
    "- MALLET\n",
    "- More ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling with Gensim\n",
    "\n",
    "- https://pypi.python.org/pypi/gensim/0.13.1\n",
    "- download **gensim-0.13.1.win-amd64-py2.7.exe (md5)** and install **gensim** by doubleclick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-3.0.0-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (13.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 13.1MB 45kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /anaconda/lib/python2.7/site-packages (from gensim)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /anaconda/lib/python2.7/site-packages (from gensim)\n",
      "Requirement already satisfied: six>=1.5.0 in /anaconda/lib/python2.7/site-packages (from gensim)\n",
      "Collecting smart-open>=1.2.1 (from gensim)\n",
      "  Downloading smart_open-1.5.3.tar.gz\n",
      "Requirement already satisfied: boto>=2.32 in /anaconda/lib/python2.7/site-packages (from smart-open>=1.2.1->gensim)\n",
      "Collecting bz2file (from smart-open>=1.2.1->gensim)\n",
      "  Downloading bz2file-0.98.tar.gz\n",
      "Requirement already satisfied: requests in /anaconda/lib/python2.7/site-packages (from smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda/lib/python2.7/site-packages (from requests->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/lib/python2.7/site-packages (from requests->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /anaconda/lib/python2.7/site-packages (from requests->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /anaconda/lib/python2.7/site-packages (from requests->smart-open>=1.2.1->gensim)\n",
      "Building wheels for collected packages: smart-open, bz2file\n",
      "  Running setup.py bdist_wheel for smart-open ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/linlyn/Library/Caches/pip/wheels/b0/81/ad/856aade935fceaab491a800ec4de58edb8642afa4c4ba91a00\n",
      "  Running setup.py bdist_wheel for bz2file ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/linlyn/Library/Caches/pip/wheels/31/9c/20/996d65ca104cbca940b1b053299b68459391c01c774d073126\n",
      "Successfully built smart-open bz2file\n",
      "Installing collected packages: bz2file, smart-open, gensim\n",
      "Successfully installed bz2file-0.98 gensim-3.0.0 smart-open-1.5.3\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.0\n"
     ]
    }
   ],
   "source": [
    "# Below is the version of Gensim (Python package for Topic Modeling) I am using in this example\n",
    "import gensim\n",
    "print gensim.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import ldamodel\n",
    "import numpy\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # To ignore all warnings that arise here to enhance clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're setting up our corpus now. In the toy corpus presented, there are 11 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data is already clean\n",
    "texts = [['bank','river','shore','water'],\n",
    "        ['river','water','flow','fast','tree'],\n",
    "        ['bank','water','fall','flow'],\n",
    "        ['bank','bank','water','rain','river'],\n",
    "        ['river','water','mud','tree'],\n",
    "        ['money','transaction','bank','finance'],\n",
    "        ['bank','borrow','money'], \n",
    "        ['bank','finance'],\n",
    "        ['finance','money','sell','bank'],\n",
    "        ['borrow','sell', 'finance'],\n",
    "        ['bank','loan','sell']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is text processing required for topic modeling with Gensim\n",
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "11\n",
      "10\n",
      "12\n",
      "4\n",
      "15\n",
      "5\n",
      "13\n",
      "6\n",
      "0\n",
      "9\n",
      "1\n",
      "8\n",
      "7\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# dictionary is a list of integer values (vectors), which correspond to each token (or word)\n",
    "for i in dictionary:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'bank': 3,\n",
       " u'borrow': 13,\n",
       " u'fall': 7,\n",
       " u'fast': 6,\n",
       " u'finance': 12,\n",
       " u'flow': 4,\n",
       " u'loan': 15,\n",
       " u'money': 10,\n",
       " u'mud': 9,\n",
       " u'rain': 8,\n",
       " u'river': 2,\n",
       " u'sell': 14,\n",
       " u'shore': 1,\n",
       " u'transaction': 11,\n",
       " u'tree': 5,\n",
       " u'water': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view dictionary\n",
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the word \"bank\" is now recognized as the integer value \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1)]\n",
      "[(0, 1), (2, 1), (4, 1), (5, 1), (6, 1)]\n",
      "[(0, 1), (3, 1), (4, 1), (7, 1)]\n",
      "[(0, 1), (2, 1), (3, 2), (8, 1)]\n",
      "[(0, 1), (2, 1), (5, 1), (9, 1)]\n",
      "[(3, 1), (10, 1), (11, 1), (12, 1)]\n",
      "[(3, 1), (10, 1), (13, 1)]\n",
      "[(3, 1), (12, 1)]\n",
      "[(3, 1), (10, 1), (12, 1), (14, 1)]\n",
      "[(12, 1), (13, 1), (14, 1)]\n",
      "[(3, 1), (14, 1), (15, 1)]\n"
     ]
    }
   ],
   "source": [
    "# view corpus\n",
    "for i in corpus:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[(0, 1), (2, 1), **(3, 2)**, (8, 1)] : the word \"bank\" (or the integer value 3) appears twice in sentence #4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Document-term matrix (vector-space representation of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://facweb.cs.depaul.edu/mobasher/classes/csc575/assignments/a4-q1q2.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"http://facweb.cs.depaul.edu/mobasher/classes/csc575/assignments/a4-q1q2.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up the LDA model in the corpus. We set the number of topics to be 2, and expect to see one which is to do with river banks, and one to do with financial banks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numpy.random.seed(1) # setting random seed to get the same results each time. \n",
    "model = ldamodel.LdaModel(corpus, id2word=dictionary, num_topics=2, passes=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prints the topics. term-topic-distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.184*\"water\" + 0.150*\"river\" + 0.148*\"bank\" + 0.083*\"tree\" + 0.083*\"flow\" + 0.050*\"fast\" + 0.050*\"mud\" + 0.050*\"fall\" + 0.050*\"rain\" + 0.050*\"shore\"'),\n",
       " (1,\n",
       "  u'0.206*\"bank\" + 0.166*\"finance\" + 0.129*\"money\" + 0.129*\"sell\" + 0.092*\"borrow\" + 0.055*\"transaction\" + 0.055*\"loan\" + 0.019*\"shore\" + 0.019*\"rain\" + 0.019*\"fall\"')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic_0 is \"river\" characterized by the words such as water, river, bank, tree, flow, fast, and mud\n",
    "\n",
    "Topic_1 is about \"finance\" (bank, finance, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print words without probability\n",
    "for i in range(0,2):\n",
    "    topics = model.show_topic(i, 10)\n",
    "    print ','.join([str(word[0]) for word in topics])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise has shown you how to perform topic modeling with Gensim. The results show two hiddent topics in the data. One is about **river** and the other **finance**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigns the topics to the documents in corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.88427368618480195), (1, 0.11572631381519809)]\n",
      "[(0, 0.91476633640841631), (1, 0.085233663591583644)]\n",
      "[(0, 0.88369469699756775), (1, 0.11630530300243222)]\n",
      "[(0, 0.89131469242835448), (1, 0.10868530757164548)]\n",
      "[(0, 0.89772096004832613), (1, 0.10227903995167383)]\n",
      "[(0, 0.10742112643066244), (1, 0.89257887356933752)]\n",
      "[(0, 0.13644008705346489), (1, 0.863559912946535)]\n",
      "[(0, 0.18890335729688856), (1, 0.81109664270311144)]\n",
      "[(0, 0.10661051310024225), (1, 0.89338948689975783)]\n",
      "[(0, 0.12671990160814622), (1, 0.87328009839185383)]\n",
      "[(0, 0.13757016927994173), (1, 0.8624298307200583)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_corpus = model[corpus]\n",
    "\n",
    "results = []\n",
    "for i in lda_corpus:\n",
    "    print i\n",
    "    results.append(i)\n",
    "print "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document #1 is 88% topic 1 and 12% topic 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding highest value from each row\n",
    "toptopic = [max(collection, key=lambda x: x[1])[0] for collection in results]\n",
    "toptopic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And like we expected, the LDA model has given us near perfect results. The first five documents are \"river\" and the other six documents are \"finance\". 5 `river` related and 6 `finance` related."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'sell': 14, u'transaction': 11, u'money': 10, u'finance': 12, u'flow': 4, u'loan': 15, u'tree': 5, u'borrow': 13, u'fast': 6, u'water': 0, u'mud': 9, u'shore': 1, u'rain': 8, u'fall': 7, u'river': 2, u'bank': 3}\n"
     ]
    }
   ],
   "source": [
    "print dictionary.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1)],\n",
       " [(0, 1), (2, 1), (4, 1), (5, 1), (6, 1)],\n",
       " [(0, 1), (3, 1), (4, 1), (7, 1)],\n",
       " [(0, 1), (2, 1), (3, 2), (8, 1)],\n",
       " [(0, 1), (2, 1), (5, 1), (9, 1)],\n",
       " [(3, 1), (10, 1), (11, 1), (12, 1)],\n",
       " [(3, 1), (10, 1), (13, 1)],\n",
       " [(3, 1), (12, 1)],\n",
       " [(3, 1), (10, 1), (12, 1), (14, 1)],\n",
       " [(12, 1), (13, 1), (14, 1)],\n",
       " [(3, 1), (14, 1), (15, 1)]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's understand the matrix above. For example, the last line\n",
    "\n",
    "[(3, 1), (14, 1), (15, 1)]\n",
    "\n",
    "- The word ('bank') whose integer ID is 3 appears only once in document 11\n",
    "- The word ('sell') whose integer ID is 14 appears once in document 11\n",
    "\n",
    "The function doc2bow() simply counts the number of occurences of each distinct word, converts the word to its integer word id and returns the result as a sparse vector https://radimrehurek.com/gensim/tut1.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to show off the new `get_term_topics` and `get_document_topics` functionalities, and a good way to do so is to play around with words which might have different meanings in different context.\n",
    "\n",
    "The word `bank` is a good candidate here, where it can mean either the financial institution or a river bank.\n",
    "In the toy corpus presented, there are 11 documents, 5 `river` related and 6 `finance` related. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_term_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `get_term_topics` returns the odds of that particular word belonging to a particular topic. \n",
    "A few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.17002494151715156)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_term_topics('water')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Makes sense, the value for it belonging to `topic_0` is a lot more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.15048474280196972)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_term_topics('finance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.13386514906929059), (1, 0.19109000946118354)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_term_topics('bank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also works out well, the word finance is more likely to be in topic_1 to do with financial banks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is particularly interesting. Since the word bank is likely to be in both the topics, the values returned are also very similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_document_topics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_document_topics` is an already existing gensim functionality which uses the `inference` function to get the sufficient statistics and figure out the topic distribution of the document.\n",
    "\n",
    "The addition to this is the ability for us to now know the topic distribution for each word in the document. \n",
    "Let us test this with two different documents which have the word bank in it, one in the finance context and one in the river context.\n",
    "\n",
    "The `get_document_topics` method returns (along with the standard document topic proprtion) the word_type followed by a list sorted with the most likely topic ids, when `per_word_topics` is set as true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#let's declare two new documents and find out the likely topic for each document\n",
    "bow_water = ['bank','water','bank']\n",
    "bow_finance = ['bank','finance','bank']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (3, 2)]\n"
     ]
    }
   ],
   "source": [
    "bow = model.id2word.doc2bow(bow_water) # convert to bag of words format first\n",
    "print bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 is \"water\", 3 is \"bank\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, [0]), (3, [0, 1])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topics, word_topics, phi_values = model.get_document_topics(bow, per_word_topics=True)\n",
    "word_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.75955178281199542), (1, 0.24044821718800463)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 2), (12, 1)]\n"
     ]
    }
   ],
   "source": [
    "bow = model.id2word.doc2bow(bow_finance) # convert to bag of words format first\n",
    "print bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what does that output mean? It means that like `word_type 1`, our `word_type` `3`, which is the word `bank`, is more likely to be in `topic_0` than `topic_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, [1, 0]), (12, [1])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topics, word_topics, phi_values = model.get_document_topics(bow, per_word_topics=True)\n",
    "word_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You must have noticed that while we unpacked into `doc_topics` and `word_topics`, there is another variable - `phi_values`. Like the name suggests, phi_values contains the phi values for each topic for that particular word, scaled by feature length. **Phi** is essentially **the probability of that word in that document belonging to a particular topic**. The next few lines should illustrate this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.1502293463768338), (1, 0.84977065362316628)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, [(0, 0.098302410617005551), (1, 1.9016975893829946)]),\n",
       " (12, [(1, 0.99756820057045625)])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that `word_type` 0 has the following phi_values for each of the topics. \n",
    "What is intresting to note is `word_type` 3 - because it has 2 occurences (i.e, the word `bank` appears twice in the bow), we can see that the scaling by feature length is very evident. The sum of the phi_values is 2, and not 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know exactly what `get_document_topics` does, let us now do the same with our second document, `bow_finance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the word bank is now used in the financial context, it immedietly swaps to being more likely associated with `topic_1`.\n",
    "\n",
    "We've seen quite clearly that based on the context, the most likely topic associated with a word can change. \n",
    "This differs from our previous method, `get_term_topics`, where it is a 'static' topic distribution. \n",
    "\n",
    "It must also be noted that because the gensim implementation of LDA uses Variational Bayes sampling, a `word_type` in a document is only given one topic distribution. For example, the sentence 'the bank by the river bank' is likely to be assigned to `topic_0`, and each of the bank word instances have the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In conclusion, \n",
    "- bow_water = ['bank','water','bank'] is close to topic_0\n",
    "- bow_finance = ['bank','finance','bank'] is close to topic_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pyldavis** is a Python package visualizing the results of topics modeling (https://github.com/bmabey/pyLDAvis)\n",
    "\n",
    "To install, **pip install pyldavis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyldavis\n",
      "  Downloading pyLDAvis-2.1.1.tar.gz (1.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.6MB 310kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.23.0 in /anaconda/lib/python2.7/site-packages (from pyldavis)\n",
      "Requirement already satisfied: numpy>=1.9.2 in /anaconda/lib/python2.7/site-packages (from pyldavis)\n",
      "Requirement already satisfied: scipy>=0.18.0 in /anaconda/lib/python2.7/site-packages (from pyldavis)\n",
      "Requirement already satisfied: pandas>=0.17.0 in /anaconda/lib/python2.7/site-packages (from pyldavis)\n",
      "Requirement already satisfied: joblib>=0.8.4 in /anaconda/lib/python2.7/site-packages (from pyldavis)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in /anaconda/lib/python2.7/site-packages (from pyldavis)\n",
      "Requirement already satisfied: numexpr in /anaconda/lib/python2.7/site-packages (from pyldavis)\n",
      "Requirement already satisfied: pytest in /anaconda/lib/python2.7/site-packages (from pyldavis)\n",
      "Collecting future (from pyldavis)\n",
      "  Downloading future-0.16.0.tar.gz (824kB)\n",
      "\u001b[K    100% |████████████████████████████████| 829kB 586kB/s ta 0:00:011\n",
      "\u001b[?25hCollecting funcy (from pyldavis)\n",
      "  Downloading funcy-1.9.1.tar.gz\n",
      "Requirement already satisfied: python-dateutil in /anaconda/lib/python2.7/site-packages (from pandas>=0.17.0->pyldavis)\n",
      "Requirement already satisfied: pytz>=2011k in /anaconda/lib/python2.7/site-packages (from pandas>=0.17.0->pyldavis)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /anaconda/lib/python2.7/site-packages (from jinja2>=2.7.2->pyldavis)\n",
      "Requirement already satisfied: py>=1.4.29 in /anaconda/lib/python2.7/site-packages (from pytest->pyldavis)\n",
      "Requirement already satisfied: setuptools in /anaconda/lib/python2.7/site-packages/setuptools-27.2.0-py2.7.egg (from pytest->pyldavis)\n",
      "Requirement already satisfied: six>=1.5 in /anaconda/lib/python2.7/site-packages (from python-dateutil->pandas>=0.17.0->pyldavis)\n",
      "Building wheels for collected packages: pyldavis, future, funcy\n",
      "  Running setup.py bdist_wheel for pyldavis ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/linlyn/Library/Caches/pip/wheels/de/41/af/cba16e4c15ff942728f3345c8f165831b03ad7f4d87cff8b6e\n",
      "  Running setup.py bdist_wheel for future ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/linlyn/Library/Caches/pip/wheels/c2/50/7c/0d83b4baac4f63ff7a765bd16390d2ab43c93587fac9d6017a\n",
      "  Running setup.py bdist_wheel for funcy ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/linlyn/Library/Caches/pip/wheels/0a/7e/0f/7e6946d9291cf9963926645a1dee5dd5a9c522daa5a659e0a2\n",
      "Successfully built pyldavis future funcy\n",
      "Installing collected packages: future, funcy, pyldavis\n",
      "Successfully installed funcy-1.9.1 future-0.16.0 pyldavis-2.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyldavis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/pyLDAvis/_prepare.py:387: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  topic_term_dists = topic_term_dists.ix[topic_order]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1713344890349602716882288\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1713344890349602716882288_data = {\"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2], \"token.table\": {\"Topic\": [1, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1], \"Freq\": [0.419147967536753, 0.5588639567156707, 0.9471141294153232, 0.6859666073691133, 0.6858956082963109, 0.8559885064564231, 0.9100069436547024, 0.7066656477315809, 0.7122184563255173, 0.685927502092003, 0.685971412235436, 0.8157554149208215, 0.7122117318666106, 0.6859717805721961, 0.7067186514673455, 0.9099934110621233, 0.9054928296553182], \"Term\": [\"bank\", \"bank\", \"borrow\", \"fall\", \"fast\", \"finance\", \"flow\", \"loan\", \"money\", \"mud\", \"rain\", \"river\", \"sell\", \"shore\", \"transaction\", \"tree\", \"water\"]}, \"mdsDat\": {\"y\": [0.0, 0.0], \"cluster\": [1, 1], \"Freq\": [53.9741148510524, 46.025885148947594], \"topics\": [1, 2], \"x\": [0.10976115581354821, -0.10976115581354821]}, \"R\": 16, \"lambda.step\": 0.01, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"], \"Term\": [\"finance\", \"water\", \"money\", \"sell\", \"river\", \"borrow\", \"tree\", \"flow\", \"transaction\", \"loan\", \"bank\", \"fast\", \"mud\", \"fall\", \"rain\", \"shore\", \"water\", \"river\", \"tree\", \"flow\", \"fast\", \"mud\", \"fall\", \"rain\", \"shore\", \"bank\", \"loan\", \"transaction\", \"borrow\", \"sell\", \"money\", \"finance\", \"finance\", \"money\", \"sell\", \"borrow\", \"transaction\", \"loan\", \"bank\", \"shore\", \"rain\", \"fall\", \"mud\", \"fast\", \"flow\", \"tree\", \"river\", \"water\"], \"loglift\": [16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.5332, 0.5155, 0.442, 0.4417, 0.3408, 0.3398, 0.3386, 0.3384, 0.3384, -0.1651, -0.7095, -0.7142, -1.1075, -1.3951, -1.3963, -1.6152, 0.6624, 0.6326, 0.6324, 0.5796, 0.4691, 0.4674, 0.1642, -0.6392, -0.6392, -0.6397, -0.6436, -0.6467, -1.0533, -1.0548, -1.5656, -1.7485], \"Freq\": [3.0, 4.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 1.0, 7.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.063645402390934, 3.323892696453855, 1.845534030718268, 1.8449766664313532, 1.1064755857309367, 1.1053195239098976, 1.10390221255681, 1.103728078624671, 1.10371472977366, 3.2751534588627216, 0.37571282434387154, 0.3739029141075259, 0.37655061249568705, 0.3755844061384555, 0.375132262857055, 0.37616168353578205, 3.1285582716646037, 2.432994909693927, 2.432569279786193, 1.7351273129879599, 1.0410873340254765, 1.0393835556910596, 3.882223487589834, 0.35407118550970706, 0.35405861942621575, 0.3538946965891007, 0.3525604954071739, 0.35147222426290436, 0.35280876141137146, 0.3522840805861273, 0.35368019503738285, 0.35383850139947626], \"Total\": [3.0, 4.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 1.0, 7.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.41748390379041, 3.677572891491238, 2.1978181113043953, 2.1977854278427245, 1.4579478099938412, 1.4578800193170716, 1.4577969091459109, 1.457786698050887, 1.4577859152833672, 7.157376946452556, 1.4150963800349312, 1.4149902481330023, 2.111677925483647, 2.8081536859246485, 2.808127172550982, 3.5047199552003856, 3.5047199552003856, 2.808127172550982, 2.8081536859246485, 2.111677925483647, 1.4149902481330023, 1.4150963800349312, 7.157376946452556, 1.4577859152833672, 1.457786698050887, 1.4577969091459109, 1.4578800193170716, 1.4579478099938412, 2.1977854278427245, 2.1978181113043953, 3.677572891491238, 4.41748390379041], \"logprob\": [16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -1.6948, -1.8958, -2.4841, -2.4844, -2.9957, -2.9968, -2.9981, -2.9982, -2.9982, -1.9105, -4.0758, -4.0807, -4.0736, -4.0762, -4.0774, -4.0746, -1.797, -2.0485, -2.0487, -2.3865, -2.8973, -2.899, -1.5812, -3.9759, -3.9759, -3.9764, -3.9801, -3.9832, -3.9794, -3.9809, -3.977, -3.9765]}};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1713344890349602716882288\", ldavis_el1713344890349602716882288_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1713344890349602716882288\", ldavis_el1713344890349602716882288_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1713344890349602716882288\", ldavis_el1713344890349602716882288_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=            Freq  cluster  topics         x    y\n",
       "topic                                           \n",
       "0      53.974115        1       1  0.109761  0.0\n",
       "1      46.025885        1       2 -0.109761  0.0, topic_info=     Category      Freq         Term     Total  loglift  logprob\n",
       "term                                                            \n",
       "3     Default  3.000000      finance  3.000000  16.0000  16.0000\n",
       "9     Default  4.000000        water  4.000000  15.0000  15.0000\n",
       "2     Default  2.000000        money  2.000000  14.0000  14.0000\n",
       "0     Default  2.000000         sell  2.000000  13.0000  13.0000\n",
       "14    Default  3.000000        river  3.000000  12.0000  12.0000\n",
       "7     Default  2.000000       borrow  2.000000  11.0000  11.0000\n",
       "6     Default  2.000000         tree  2.000000  10.0000  10.0000\n",
       "4     Default  2.000000         flow  2.000000   9.0000   9.0000\n",
       "1     Default  1.000000  transaction  1.000000   8.0000   8.0000\n",
       "5     Default  1.000000         loan  1.000000   7.0000   7.0000\n",
       "15    Default  7.000000         bank  7.000000   6.0000   6.0000\n",
       "8     Default  1.000000         fast  1.000000   5.0000   5.0000\n",
       "10    Default  1.000000          mud  1.000000   4.0000   4.0000\n",
       "13    Default  1.000000         fall  1.000000   3.0000   3.0000\n",
       "12    Default  1.000000         rain  1.000000   2.0000   2.0000\n",
       "11    Default  1.000000        shore  1.000000   1.0000   1.0000\n",
       "9      Topic1  4.063645        water  4.417484   0.5332  -1.6948\n",
       "14     Topic1  3.323893        river  3.677573   0.5155  -1.8958\n",
       "6      Topic1  1.845534         tree  2.197818   0.4420  -2.4841\n",
       "4      Topic1  1.844977         flow  2.197785   0.4417  -2.4844\n",
       "8      Topic1  1.106476         fast  1.457948   0.3408  -2.9957\n",
       "10     Topic1  1.105320          mud  1.457880   0.3398  -2.9968\n",
       "13     Topic1  1.103902         fall  1.457797   0.3386  -2.9981\n",
       "12     Topic1  1.103728         rain  1.457787   0.3384  -2.9982\n",
       "11     Topic1  1.103715        shore  1.457786   0.3384  -2.9982\n",
       "15     Topic1  3.275153         bank  7.157377  -0.1651  -1.9105\n",
       "5      Topic1  0.375713         loan  1.415096  -0.7095  -4.0758\n",
       "1      Topic1  0.373903  transaction  1.414990  -0.7142  -4.0807\n",
       "7      Topic1  0.376551       borrow  2.111678  -1.1075  -4.0736\n",
       "0      Topic1  0.375584         sell  2.808154  -1.3951  -4.0762\n",
       "2      Topic1  0.375132        money  2.808127  -1.3963  -4.0774\n",
       "3      Topic1  0.376162      finance  3.504720  -1.6152  -4.0746\n",
       "3      Topic2  3.128558      finance  3.504720   0.6624  -1.7970\n",
       "2      Topic2  2.432995        money  2.808127   0.6326  -2.0485\n",
       "0      Topic2  2.432569         sell  2.808154   0.6324  -2.0487\n",
       "7      Topic2  1.735127       borrow  2.111678   0.5796  -2.3865\n",
       "1      Topic2  1.041087  transaction  1.414990   0.4691  -2.8973\n",
       "5      Topic2  1.039384         loan  1.415096   0.4674  -2.8990\n",
       "15     Topic2  3.882223         bank  7.157377   0.1642  -1.5812\n",
       "11     Topic2  0.354071        shore  1.457786  -0.6392  -3.9759\n",
       "12     Topic2  0.354059         rain  1.457787  -0.6392  -3.9759\n",
       "13     Topic2  0.353895         fall  1.457797  -0.6397  -3.9764\n",
       "10     Topic2  0.352560          mud  1.457880  -0.6436  -3.9801\n",
       "8      Topic2  0.351472         fast  1.457948  -0.6467  -3.9832\n",
       "4      Topic2  0.352809         flow  2.197785  -1.0533  -3.9794\n",
       "6      Topic2  0.352284         tree  2.197818  -1.0548  -3.9809\n",
       "14     Topic2  0.353680        river  3.677573  -1.5656  -3.9770\n",
       "9      Topic2  0.353839        water  4.417484  -1.7485  -3.9765, token_table=      Topic      Freq         Term\n",
       "term                              \n",
       "15        1  0.419148         bank\n",
       "15        2  0.558864         bank\n",
       "7         2  0.947114       borrow\n",
       "13        1  0.685967         fall\n",
       "8         1  0.685896         fast\n",
       "3         2  0.855989      finance\n",
       "4         1  0.910007         flow\n",
       "5         2  0.706666         loan\n",
       "2         2  0.712218        money\n",
       "10        1  0.685928          mud\n",
       "12        1  0.685971         rain\n",
       "14        1  0.815755        river\n",
       "0         2  0.712212         sell\n",
       "11        1  0.685972        shore\n",
       "1         2  0.706719  transaction\n",
       "6         1  0.909993         tree\n",
       "9         1  0.905493        water, R=16, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis.gensim\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.gensim.prepare(model, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix 4 How to Determine Optional K Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Human judgement\n",
    "- Semantic coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.wrappers import LdaVowpalWabbit, LdaMallet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two different LDA Topic models are initialized. A good one and bad one. A \"good\" topic model (k = 2); a \"bad\" topic model (k = 6).\n",
    "\n",
    "The method below will determine which k value delivers **highly coherent topics**. For example, a topic with words such as \"river\", \"water\", and \"bank\" is considered a coherent topic. On the other hand, a topic with words such as \"river\", \"finance\", and \"biology\" may not be coherent.\n",
    "\n",
    "This measure is called **semantic coherence**.\n",
    "\n",
    "References \n",
    "\n",
    "- http://dirichlet.net/pdf/mimno11optimizing.pdf\n",
    "- https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/topic_coherence_tutorial.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numpy.random.seed(1) # setting random seed to get the same results each time. We normally do not include this line.\n",
    "goodLdaModel = ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=2, passes=20)\n",
    "badLdaModel = ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=6, passes=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### u_mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-17.5796583466\n",
      "-17.648462136\n"
     ]
    }
   ],
   "source": [
    "goodcm = CoherenceModel(model=goodLdaModel, corpus=corpus, dictionary=dictionary, coherence='u_mass')\n",
    "badcm = CoherenceModel(model=badLdaModel, corpus=corpus, dictionary=dictionary, coherence='u_mass')\n",
    "print goodcm.get_coherence()\n",
    "print badcm.get_coherence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good model (2 topics) is better than bad model (6 topics) in terms of semantic coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's develop several models and find out their coherence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numpy.random.seed(1) # setting random seed to get the same results each time. We normally do not include this line.\n",
    "# we are considering 2 through 7; For a large dataset (or corpus), we would consider 2 through 100). This process would take a very long time\n",
    "for k in range(2,7):\n",
    "    goodLdaModel = ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=k, passes=20)\n",
    "    goodcm = CoherenceModel(model=goodLdaModel, corpus=corpus, dictionary=dictionary, coherence='u_mass')\n",
    "    print goodcm.get_coherence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows 2 as the optimal toic number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix 5 Parameters of LDA\n",
    "\n",
    "Number of Topics – Number of topics to be extracted from the corpus. \n",
    "\n",
    "Number of Iterations / passes – Maximum number of iterations allowed to LDA algorithm for convergence.\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2016/08/beginners-guide-to-topic-modeling-in-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
