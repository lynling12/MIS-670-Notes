{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Web Crawling\n",
    "\n",
    "- A web scraping technique, but for large collections of data\n",
    "- Combines **XPath** and **For Loop** statement\n",
    "- Knowledge of **Regular Expression** is plus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Copyright laws: \n",
    "* Using the crawled data for **commerical service** is violating copyright laws\n",
    "* Web crawling in this course is for **educational purpose** only. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Example: IMDb\n",
    "- Previously, we scraped http://www.imdb.com/search/title?at=0&sort=num_votes,desc&start=1&title_type=feature&year=1950,2012\n",
    "- There are over 200,000 webpages for this movie information. To collect data from those webpages, you need **web crawling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Web Scraping (first webpage only) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import python packages\n",
    "import requests\n",
    "from lxml import html\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "r = requests.get('http://www.imdb.com/search/title?at=0&sort=num_votes,desc&start=1&title_type=feature&year=1950,2012')\n",
    "data = html.fromstring(r.text)\n",
    "\n",
    "# Xpath\n",
    "alldata =[]\n",
    "\n",
    "for i in data.xpath(\"//h3[@class='lister-item-header']\"):\n",
    "    title = i.xpath('a/text()')  \n",
    "    url = i.xpath('a/@href')        \n",
    "    year = i.xpath('span[2]/text()')   \n",
    "    print title, url, year\n",
    "    alldata.append([title, url, year])\n",
    "    \n",
    "len(alldata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Crawling multiple pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Review: for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# loop 5 times\n",
    "for i in range(1,5):\n",
    "    print i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "When you visit the web site (IMDb), the webpages have a certain pattern:\n",
    "\n",
    "- http://www.imdb.com/search/title?at=0&sort=num_votes,desc&start=1&title_type=feature&year=1950,2012\n",
    "- http://www.imdb.com/search/title?at=0&sort=num_votes,desc&start=51&title_type=feature&year=1950,2012\n",
    "- http://www.imdb.com/search/title?at=0&sort=num_votes,desc&start=101&title_type=feature&year=1950,2012\n",
    " \n",
    "The number after **start=** increases by 50. Then, we can try something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "web = \"http://www.imdb.com/search/title?at=0&sort=num_votes,desc&start=%s&title_type=feature&year=1950,2012\"\n",
    "\n",
    "for page in range(1,150,50):\n",
    "    print web % page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, we will add XPaths into the loop statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "alldata =[]\n",
    "\n",
    "web = \"http://www.imdb.com/search/title?at=0&sort=num_votes,desc&start=%s&title_type=feature&year=1950,2012\"\n",
    "\n",
    "for page in range(1,150,50):\n",
    "    url = web % page\n",
    "    data = html.fromstring(requests.get(url).text)\n",
    "    #xpath\n",
    "    for i in data.xpath(\"//h3[@class='lister-item-header']\"):\n",
    "        title = i.xpath('a/text()')  \n",
    "        url = i.xpath('a/@href')        \n",
    "        year = i.xpath('span[2]/text()')   \n",
    "        print title, url, year\n",
    "        alldata.append([title, url, year])\n",
    "    \n",
    "len(alldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(alldata)       \n",
    "df.to_csv(\"data/output_imdb_crawling.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# OpenCorporates (The Open Database of the Corporate World)\n",
    "\n",
    "- We're interested in businesses in Kansas. The url is https://opencorporates.com/companies/us_ks?current_status=Active+And+In+Good+Standing&page=1&q=\n",
    "- There are many more webpages (+1000).\n",
    "- For example, the second web page's URL looks like this https://opencorporates.com/companies/us_ks?current_status=Active+And+In+Good+Standing&page=2&q="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Web Scraping (first webpage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "r = requests.get('https://opencorporates.com/companies/us_ks?current_status=Active+And+In+Good+Standing&page=1&q=')\n",
    "data = html.fromstring(r.text)\n",
    "\n",
    "# Xpath\n",
    "\n",
    "for i in data.xpath(\"//li[contains(@class,'search-result')]\"):\n",
    "    title = i.xpath('a[2]/text()')   \n",
    "    url = i.xpath('span[@class=\"address\"]/a/@href')       \n",
    "    address = i.xpath('span[@class=\"address\"]/text()') \n",
    "    print title, url, address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Crawling multiple pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# generating urls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Rotten Tomatoes Movie Reviews\n",
    "\n",
    "- Now, we're familar with how XPath works so we will do coding without using Google Sheets. \n",
    "- Go to https://www.rottentomatoes.com/m/interstellar_2014/reviews/?page=1&sort=\n",
    "- Collect reviewer name, fresh/rotten, review, and date.\n",
    "- There are 15 more webpages of reviews for this movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "r = requests.get('https://www.rottentomatoes.com/m/interstellar_2014/reviews/?page=1&sort=')\n",
    "data = html.fromstring(r.text)\n",
    "\n",
    "for i in data.xpath(\"//div[@class='row review_table_row']\"):\n",
    "    name = i.xpath('div/div/a[contains(@href, \"critic\")]/text()')\n",
    "    sentiment = i.xpath('div[@class=\"col-xs-16 review_container\"]/div[1]/@class')\n",
    "    date = i.xpath('div[@class=\"col-xs-16 review_container\"]/div[2]/div[1]/text()')\n",
    "    review = i.xpath('div[@class=\"col-xs-16 review_container\"]/div[2]/div[2]/div[1]/text()')\n",
    "    print name, sentiment, date, review   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Crawling multiple pages: Your Turn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# data frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# remove brackets\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# remove single quotation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# remove \"review_icon icon small\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# renaming columns 0: 'reviewer', 1: 'sentiment', 2: 'date', 3:'review'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# pivot table by date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# pivot table by sentiment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# word frequency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# data frame to list\n",
    "\n",
    "review = df['review'].tolist()\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in review:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import FreqDist, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "# convert to string\n",
    "tokens = str(review)\n",
    "\n",
    "#lowecases\n",
    "tokens = tokens.lower()\n",
    "\n",
    "#tokenization\n",
    "tokens = word_tokenize(tokens)\n",
    "\n",
    "#Remove stopwords\n",
    "tokens = (word for word in tokens if word not in stopwords.words('english'))\n",
    "\n",
    "# Filter non-alphanumeric characters from tokens\n",
    "tokens = (word for word in tokens if word.isalpha())\n",
    "\n",
    "#remove short words\n",
    "tokens = [ word for word in tokens if len(word) >= 2 ]\n",
    "\n",
    "#Create your bigrams ... bigrams are two tokens\n",
    "#bgs = nltk.bigrams(tokens)\n",
    "\n",
    "#compute frequency distribution for all the bigrams in the text\n",
    "fdist_h = nltk.FreqDist(tokens)\n",
    "fdist_h.most_common(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
