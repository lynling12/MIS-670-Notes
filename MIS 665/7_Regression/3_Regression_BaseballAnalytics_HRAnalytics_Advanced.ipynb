{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Regression Techniques \n",
    "\n",
    "While multiple regression is better than univariate regression because the former finds a model solution with **lower SSE** (higher r-squared). But, if there are **too many X variables (e.g., > 10) in a regression model**, the model becomes **too complex (or overfitting) to be useful** in practice due to **multicollinearity and difficulity of interpretation**. This problem is also known as **\"curse of high dimensionality\"**\n",
    "\n",
    "Thus, **more advanced regression would be needed to deal with this issue**\n",
    "\n",
    "> ## 1. Regularization \n",
    "> - refers to **the process of penalizing the model with too many redundant variables (or highly correlated variables)**\n",
    "> - the goal is developing the regression model with **low SSE** and **simplicity (fewer X variables or predictors)** \n",
    "> - **two types of regression include regulariation in their objective function: Lasso and Ridge**\n",
    "> - http://scikit-learn.org/stable/modules/linear_model.html\n",
    "\n",
    "> ## 2. Feature selection\n",
    "> - refers to **the process of selecting the most useful predictors**, helping analysts understand what predictors matter in predicting y value\n",
    "> - the goal is developing the **simple** regression model with the **user specificed number of predictors**.\n",
    "> - f_regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso regression (Regularization)\n",
    "\n",
    "- (Least Absolute Shrinkage and Selection Operator) is one of the **regression models with regularization**\n",
    "- Finds the model solution with **fewer X variables**\n",
    "\n",
    "> #### How does Lasso work?#### \n",
    "\n",
    "> - Remember that the goal of regression is **Minimize SSE** and more predictors is likely to reduce **SSE**\n",
    "> - Thus, Lasso includes **regularization** or **a mechanism of penalizing adding too many variables**. \n",
    "\n",
    "                  minimize (SSE  + alpha|coefficient|)\n",
    "\n",
    "                  where alpha = parameter for penalizing adding more coefficients\n",
    "\n",
    "> - This approach reinforces the Lasso regression to consider fewer predictors (simpler regression model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#regression packages\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "#lasso regression\n",
    "from sklearn import linear_model\n",
    "\n",
    "#f_regression (feature selection)\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# recursive feature selection (feature selection)\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearID</th>\n",
       "      <th>teamID</th>\n",
       "      <th>Rank</th>\n",
       "      <th>R</th>\n",
       "      <th>RA</th>\n",
       "      <th>G</th>\n",
       "      <th>W</th>\n",
       "      <th>H</th>\n",
       "      <th>BB</th>\n",
       "      <th>HBP</th>\n",
       "      <th>AB</th>\n",
       "      <th>SF</th>\n",
       "      <th>HR</th>\n",
       "      <th>2B</th>\n",
       "      <th>3B</th>\n",
       "      <th>salary</th>\n",
       "      <th>BA</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>CHA</td>\n",
       "      <td>1</td>\n",
       "      <td>978</td>\n",
       "      <td>839</td>\n",
       "      <td>162</td>\n",
       "      <td>95</td>\n",
       "      <td>1615</td>\n",
       "      <td>591</td>\n",
       "      <td>53</td>\n",
       "      <td>5646</td>\n",
       "      <td>61</td>\n",
       "      <td>216</td>\n",
       "      <td>325</td>\n",
       "      <td>33</td>\n",
       "      <td>31133500</td>\n",
       "      <td>0.286043</td>\n",
       "      <td>0.355692</td>\n",
       "      <td>0.470067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>CLE</td>\n",
       "      <td>2</td>\n",
       "      <td>950</td>\n",
       "      <td>816</td>\n",
       "      <td>162</td>\n",
       "      <td>90</td>\n",
       "      <td>1639</td>\n",
       "      <td>685</td>\n",
       "      <td>51</td>\n",
       "      <td>5683</td>\n",
       "      <td>52</td>\n",
       "      <td>221</td>\n",
       "      <td>310</td>\n",
       "      <td>30</td>\n",
       "      <td>75880771</td>\n",
       "      <td>0.288404</td>\n",
       "      <td>0.367022</td>\n",
       "      <td>0.470174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>DET</td>\n",
       "      <td>3</td>\n",
       "      <td>823</td>\n",
       "      <td>827</td>\n",
       "      <td>162</td>\n",
       "      <td>79</td>\n",
       "      <td>1553</td>\n",
       "      <td>562</td>\n",
       "      <td>43</td>\n",
       "      <td>5644</td>\n",
       "      <td>49</td>\n",
       "      <td>177</td>\n",
       "      <td>307</td>\n",
       "      <td>41</td>\n",
       "      <td>58265167</td>\n",
       "      <td>0.275159</td>\n",
       "      <td>0.342648</td>\n",
       "      <td>0.438164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>KCA</td>\n",
       "      <td>4</td>\n",
       "      <td>879</td>\n",
       "      <td>930</td>\n",
       "      <td>162</td>\n",
       "      <td>77</td>\n",
       "      <td>1644</td>\n",
       "      <td>511</td>\n",
       "      <td>48</td>\n",
       "      <td>5709</td>\n",
       "      <td>70</td>\n",
       "      <td>150</td>\n",
       "      <td>281</td>\n",
       "      <td>27</td>\n",
       "      <td>23433000</td>\n",
       "      <td>0.287966</td>\n",
       "      <td>0.347586</td>\n",
       "      <td>0.425469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>MIN</td>\n",
       "      <td>5</td>\n",
       "      <td>748</td>\n",
       "      <td>880</td>\n",
       "      <td>162</td>\n",
       "      <td>69</td>\n",
       "      <td>1516</td>\n",
       "      <td>556</td>\n",
       "      <td>35</td>\n",
       "      <td>5615</td>\n",
       "      <td>51</td>\n",
       "      <td>116</td>\n",
       "      <td>325</td>\n",
       "      <td>49</td>\n",
       "      <td>16519500</td>\n",
       "      <td>0.269991</td>\n",
       "      <td>0.336743</td>\n",
       "      <td>0.407302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   yearID teamID  Rank    R   RA    G   W     H   BB  HBP    AB  SF   HR   2B  \\\n",
       "0    2000    CHA     1  978  839  162  95  1615  591   53  5646  61  216  325   \n",
       "1    2000    CLE     2  950  816  162  90  1639  685   51  5683  52  221  310   \n",
       "2    2000    DET     3  823  827  162  79  1553  562   43  5644  49  177  307   \n",
       "3    2000    KCA     4  879  930  162  77  1644  511   48  5709  70  150  281   \n",
       "4    2000    MIN     5  748  880  162  69  1516  556   35  5615  51  116  325   \n",
       "\n",
       "   3B    salary        BA       OBP       SLG  \n",
       "0  33  31133500  0.286043  0.355692  0.470067  \n",
       "1  30  75880771  0.288404  0.367022  0.470174  \n",
       "2  41  58265167  0.275159  0.342648  0.438164  \n",
       "3  27  23433000  0.287966  0.347586  0.425469  \n",
       "4  49  16519500  0.269991  0.336743  0.407302  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams = pd.read_csv(\"data/baseball.csv\")\n",
    "teams.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Below is an explanation of the teams DataFrame attribtues.\n",
    "\n",
    "yearID: Year\n",
    "teamID: Team\n",
    "Rank: Position in final standings\n",
    "R: Runs scored\n",
    "RA: Opponents runs scored\n",
    "G: Games played\n",
    "W: Wins\n",
    "H: Hits by batters\n",
    "BB: Walks by batters\n",
    "HBP: Batters hit by pitch\n",
    "AB: At bats\n",
    "SF: Sacrifice flies\n",
    "HR: Homeruns by batters\n",
    "2B: Doubles\n",
    "3B: Triples\n",
    "Batting Average (BA) = H/AB    \n",
    "On Base Percentage (OBP) = (H+BB+HBP)/(AB+BB+HBP+SF)\n",
    "Slugging Percentage (SLG) = H+2B+(2*3B)+(3*HR)/AB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Base Percentage (OBP, On Base Average, OBA) is a measure of how often a batter reaches base. \n",
    "\n",
    "The full formula is OBP = (Hits + Walks + Hit by Pitch) / (At Bats + Walks + Hit by Pitch + Sacrifice Flies). Batters are not credited with reaching base on an error or fielder's choice, and they are not charged with an opportunity if they make a sacrifice bunt.\n",
    "\n",
    "All Time Leaders\n",
    "Ted Williams\t.482\t(career)\n",
    "Barry Bonds\t    .609\t(2004 season)\n",
    "\n",
    "http://www.baseball-reference.com/bullpen/On_base_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "      <th>RA</th>\n",
       "      <th>G</th>\n",
       "      <th>W</th>\n",
       "      <th>H</th>\n",
       "      <th>BB</th>\n",
       "      <th>HBP</th>\n",
       "      <th>AB</th>\n",
       "      <th>SF</th>\n",
       "      <th>HR</th>\n",
       "      <th>2B</th>\n",
       "      <th>3B</th>\n",
       "      <th>salary</th>\n",
       "      <th>BA</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>978</td>\n",
       "      <td>839</td>\n",
       "      <td>162</td>\n",
       "      <td>95</td>\n",
       "      <td>1615</td>\n",
       "      <td>591</td>\n",
       "      <td>53</td>\n",
       "      <td>5646</td>\n",
       "      <td>61</td>\n",
       "      <td>216</td>\n",
       "      <td>325</td>\n",
       "      <td>33</td>\n",
       "      <td>31133500</td>\n",
       "      <td>0.286043</td>\n",
       "      <td>0.355692</td>\n",
       "      <td>0.470067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>950</td>\n",
       "      <td>816</td>\n",
       "      <td>162</td>\n",
       "      <td>90</td>\n",
       "      <td>1639</td>\n",
       "      <td>685</td>\n",
       "      <td>51</td>\n",
       "      <td>5683</td>\n",
       "      <td>52</td>\n",
       "      <td>221</td>\n",
       "      <td>310</td>\n",
       "      <td>30</td>\n",
       "      <td>75880771</td>\n",
       "      <td>0.288404</td>\n",
       "      <td>0.367022</td>\n",
       "      <td>0.470174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     R   RA    G   W     H   BB  HBP    AB  SF   HR   2B  3B    salary  \\\n",
       "0  978  839  162  95  1615  591   53  5646  61  216  325  33  31133500   \n",
       "1  950  816  162  90  1639  685   51  5683  52  221  310  30  75880771   \n",
       "\n",
       "         BA       OBP       SLG  \n",
       "0  0.286043  0.355692  0.470067  \n",
       "1  0.288404  0.367022  0.470174  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams = teams.drop(['yearID', 'teamID', 'Rank'], axis=1)\n",
    "teams.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#assigning columns to X and Y variables\n",
    "y = teams['R'] \n",
    "X = teams.drop(['R'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fit the model\n",
    "model1 = linear_model.Lasso(alpha=1)         #higher alpha (penality parameter), fewer predictors\n",
    "model1.fit(X, y)\n",
    "model1_y = model1.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:  [  2.12210981e-01   0.00000000e+00   2.11287738e+00   4.70584673e-01\n",
      "   2.42458543e-01   2.96796937e-01  -5.42432118e-02   5.57796970e-01\n",
      "   7.16499037e-01   1.64546847e-01   6.17523323e-01  -2.56238003e-08\n",
      "  -0.00000000e+00  -0.00000000e+00   0.00000000e+00]\n",
      "y-intercept  -321.284856921\n"
     ]
    }
   ],
   "source": [
    "print 'Coefficients: ', model1.coef_\n",
    "print \"y-intercept \", model1.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('RA', '0.212'),\n",
       " ('G', '0.000'),\n",
       " ('W', '2.113'),\n",
       " ('H', '0.471'),\n",
       " ('BB', '0.242'),\n",
       " ('HBP', '0.297'),\n",
       " ('AB', '-0.054'),\n",
       " ('SF', '0.558'),\n",
       " ('HR', '0.716'),\n",
       " ('2B', '0.165'),\n",
       " ('3B', '0.618'),\n",
       " ('salary', '-0.000'),\n",
       " ('BA', '-0.000'),\n",
       " ('OBP', '-0.000'),\n",
       " ('SLG', '0.000')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef = [\"%.3f\" % i for i in model1.coef_]\n",
    "xcolumns = [ i for i in X.columns ]\n",
    "zip(xcolumns, coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression model has become a lot simpler than the full model with all X variables. Several X variables were removed from the model, including **G, AB, salary, BA, OBP, and SLG**. These removed variables have their **coefficients close to 0**.\n",
    "\n",
    "R = 0.212RA + 2.113W + 0.471H + 0.242BB + ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean square error:  399.392501942\n",
      "variance or r-squared:  0.942986315484\n"
     ]
    }
   ],
   "source": [
    "print \"mean square error: \", mean_squared_error(y, model1_y)\n",
    "print \"variance or r-squared: \", explained_variance_score(y, model1_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f_Regression (Feature Selection)\n",
    "\n",
    "- Quick linear model for testing the effect of a single predictor, sequentially for many predictors.\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html#sklearn.feature_selection.f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.35569202,  0.4700673 ],\n",
       "       [ 0.3670221 ,  0.4701742 ],\n",
       "       [ 0.34264846,  0.43816442],\n",
       "       [ 0.34758599,  0.42546856],\n",
       "       [ 0.33674285,  0.40730187],\n",
       "       [ 0.35414681,  0.449964  ],\n",
       "       [ 0.34054652,  0.42344583],\n",
       "       [ 0.34111482,  0.46926193],\n",
       "       [ 0.34057971,  0.43503334],\n",
       "       [ 0.32851105,  0.39909174],\n",
       "       [ 0.35950671,  0.45773381],\n",
       "       [ 0.36107193,  0.44151355],\n",
       "       [ 0.35235536,  0.47245913],\n",
       "       [ 0.35154394,  0.44617564],\n",
       "       [ 0.35612083,  0.4554582 ],\n",
       "       [ 0.34325522,  0.44702751],\n",
       "       [ 0.32528206,  0.40337947],\n",
       "       [ 0.36057617,  0.47666068],\n",
       "       [ 0.3385103 ,  0.423888  ],\n",
       "       [ 0.33481294,  0.41115295],\n",
       "       [ 0.34647705,  0.42867553],\n",
       "       [ 0.34601247,  0.43036821],\n",
       "       [ 0.33133117,  0.40896714],\n",
       "       [ 0.32597959,  0.43161698],\n",
       "       [ 0.32903434,  0.39956451],\n",
       "       [ 0.36170213,  0.4720058 ],\n",
       "       [ 0.34053794,  0.43094326],\n",
       "       [ 0.33338728,  0.42934684],\n",
       "       [ 0.36171213,  0.45459364],\n",
       "       [ 0.32970725,  0.40233813],\n",
       "       [ 0.34955612,  0.45767857],\n",
       "       [ 0.33668995,  0.43345324],\n",
       "       [ 0.33431904,  0.45076867],\n",
       "       [ 0.32049812,  0.40942749],\n",
       "       [ 0.31807818,  0.40935672],\n",
       "       [ 0.33387071,  0.4350009 ],\n",
       "       [ 0.33402822,  0.43907226],\n",
       "       [ 0.32528   ,  0.42963094],\n",
       "       [ 0.3190445 ,  0.37956871],\n",
       "       [ 0.31952467,  0.38776249],\n",
       "       [ 0.35994398,  0.44542254],\n",
       "       [ 0.34544025,  0.43854298],\n",
       "       [ 0.32680162,  0.40497208],\n",
       "       [ 0.34402012,  0.4707124 ],\n",
       "       [ 0.34697793,  0.45133864],\n",
       "       [ 0.3385297 ,  0.44110092],\n",
       "       [ 0.33628319,  0.42970773],\n",
       "       [ 0.3185928 ,  0.42602041],\n",
       "       [ 0.32439896,  0.4191295 ],\n",
       "       [ 0.31288755,  0.39310856],\n",
       "       [ 0.32358739,  0.41196799],\n",
       "       [ 0.32916125,  0.41404402],\n",
       "       [ 0.32290301,  0.38670086],\n",
       "       [ 0.32625735,  0.422952  ],\n",
       "       [ 0.31851728,  0.39598438],\n",
       "       [ 0.34071713,  0.44182306],\n",
       "       [ 0.34190191,  0.46008553],\n",
       "       [ 0.3229712 ,  0.42508647],\n",
       "       [ 0.33573372,  0.39894199],\n",
       "       [ 0.35408745,  0.48295255],\n",
       "       [ 0.33203505,  0.43694016],\n",
       "       [ 0.3375548 ,  0.44947292],\n",
       "       [ 0.32128713,  0.41158031],\n",
       "       [ 0.32310938,  0.39819331],\n",
       "       [ 0.3       ,  0.37939327],\n",
       "       [ 0.35442241,  0.45474022],\n",
       "       [ 0.34500792,  0.44414894],\n",
       "       [ 0.32705617,  0.42985128],\n",
       "       [ 0.30861955,  0.40302313],\n",
       "       [ 0.31394215,  0.38972163],\n",
       "       [ 0.33918035,  0.43181   ],\n",
       "       [ 0.3407136 ,  0.43254667],\n",
       "       [ 0.34978643,  0.41910576],\n",
       "       [ 0.33831954,  0.45532218],\n",
       "       [ 0.33814701,  0.42452316],\n",
       "       [ 0.33758888,  0.41740869],\n",
       "       [ 0.33041078,  0.40804388],\n",
       "       [ 0.31934459,  0.38067542],\n",
       "       [ 0.32121999,  0.41266376],\n",
       "       [ 0.32045303,  0.39021237],\n",
       "       [ 0.33138402,  0.40946315],\n",
       "       [ 0.33425594,  0.41795948],\n",
       "       [ 0.33908873,  0.42187217],\n",
       "       [ 0.33688115,  0.40302038],\n",
       "       [ 0.32230453,  0.39501456],\n",
       "       [ 0.34601855,  0.42320261],\n",
       "       [ 0.34446228,  0.44187739],\n",
       "       [ 0.31995394,  0.40925459],\n",
       "       [ 0.33704006,  0.42253266],\n",
       "       [ 0.32121311,  0.38114234],\n",
       "       [ 0.34097421,  0.43147657],\n",
       "       [ 0.33120393,  0.44578094],\n",
       "       [ 0.33630181,  0.42708333],\n",
       "       [ 0.3160723 ,  0.40111271],\n",
       "       [ 0.30008326,  0.37504574],\n",
       "       [ 0.35644028,  0.45316682],\n",
       "       [ 0.359668  ,  0.49089964],\n",
       "       [ 0.34881158,  0.45451334],\n",
       "       [ 0.32326333,  0.4054722 ],\n",
       "       [ 0.31990291,  0.40431553],\n",
       "       [ 0.32652068,  0.41677278],\n",
       "       [ 0.3439001 ,  0.41035785],\n",
       "       [ 0.33036744,  0.41279388],\n",
       "       [ 0.33003669,  0.45356638],\n",
       "       [ 0.32307189,  0.41619859],\n",
       "       [ 0.33615594,  0.43113022],\n",
       "       [ 0.35005487,  0.45380818],\n",
       "       [ 0.33809142,  0.42035478],\n",
       "       [ 0.31770833,  0.39499002],\n",
       "       [ 0.32887528,  0.41906994],\n",
       "       [ 0.34880406,  0.47548501],\n",
       "       [ 0.33278715,  0.42076503],\n",
       "       [ 0.34261174,  0.41944795],\n",
       "       [ 0.32610854,  0.40095641],\n",
       "       [ 0.31371226,  0.37427448],\n",
       "       [ 0.33828329,  0.42503666],\n",
       "       [ 0.30293378,  0.36826676],\n",
       "       [ 0.32962246,  0.41651706],\n",
       "       [ 0.34414646,  0.44545125],\n",
       "       [ 0.33317191,  0.38817574],\n",
       "       [ 0.33189103,  0.43126445],\n",
       "       [ 0.33284457,  0.45699313],\n",
       "       [ 0.35129647,  0.44397463],\n",
       "       [ 0.33670196,  0.44922639],\n",
       "       [ 0.32210044,  0.3974359 ],\n",
       "       [ 0.35293188,  0.45775285],\n",
       "       [ 0.3599877 ,  0.47237762],\n",
       "       [ 0.34450885,  0.43165969],\n",
       "       [ 0.31997361,  0.40507022],\n",
       "       [ 0.32840669,  0.40336286],\n",
       "       [ 0.34075974,  0.42907489],\n",
       "       [ 0.34317687,  0.43261173],\n",
       "       [ 0.3293759 ,  0.45663402],\n",
       "       [ 0.33090564,  0.39636491],\n",
       "       [ 0.34431234,  0.45958596],\n",
       "       [ 0.34175984,  0.4361741 ],\n",
       "       [ 0.32806706,  0.45824449],\n",
       "       [ 0.33103005,  0.41772381],\n",
       "       [ 0.32112676,  0.40105781],\n",
       "       [ 0.32066547,  0.38701441],\n",
       "       [ 0.34307152,  0.43357271],\n",
       "       [ 0.34543179,  0.44284955],\n",
       "       [ 0.32944271,  0.40648924],\n",
       "       [ 0.31747842,  0.40853218],\n",
       "       [ 0.31334879,  0.39166971],\n",
       "       [ 0.33165992,  0.42313244],\n",
       "       [ 0.35723251,  0.43797331],\n",
       "       [ 0.34227759,  0.41378073],\n",
       "       [ 0.34525337,  0.45472476],\n",
       "       [ 0.30988938,  0.39267677],\n",
       "       [ 0.32239002,  0.42485079],\n",
       "       [ 0.33445946,  0.45284364],\n",
       "       [ 0.32276423,  0.39108555],\n",
       "       [ 0.32145789,  0.42806141],\n",
       "       [ 0.31986755,  0.39614756],\n",
       "       [ 0.35471225,  0.44985775],\n",
       "       [ 0.35670684,  0.45449698],\n",
       "       [ 0.33081133,  0.40727468],\n",
       "       [ 0.32704299,  0.43397586],\n",
       "       [ 0.3287311 ,  0.42489193],\n",
       "       [ 0.32513439,  0.40878378],\n",
       "       [ 0.33008312,  0.40714413],\n",
       "       [ 0.32920045,  0.4683345 ],\n",
       "       [ 0.31726643,  0.39132014],\n",
       "       [ 0.33879073,  0.42307692],\n",
       "       [ 0.32243685,  0.40790919],\n",
       "       [ 0.33119869,  0.42272393],\n",
       "       [ 0.32430213,  0.44000716],\n",
       "       [ 0.33869683,  0.44636119],\n",
       "       [ 0.32246553,  0.40014355],\n",
       "       [ 0.33251514,  0.43510755],\n",
       "       [ 0.34840045,  0.42349332],\n",
       "       [ 0.33893329,  0.40948746],\n",
       "       [ 0.32170479,  0.41580382],\n",
       "       [ 0.321765  ,  0.38573535],\n",
       "       [ 0.33311824,  0.39131225],\n",
       "       [ 0.33248082,  0.42108108],\n",
       "       [ 0.31857668,  0.39582571],\n",
       "       [ 0.32630886,  0.39517762],\n",
       "       [ 0.33338754,  0.41050162],\n",
       "       [ 0.34661933,  0.42484827],\n",
       "       [ 0.32878271,  0.44859979],\n",
       "       [ 0.34204654,  0.46402687],\n",
       "       [ 0.34853316,  0.45719879],\n",
       "       [ 0.33246964,  0.41080694],\n",
       "       [ 0.36271609,  0.46133428],\n",
       "       [ 0.34827309,  0.46283059],\n",
       "       [ 0.35053797,  0.43513081],\n",
       "       [ 0.339303  ,  0.42352941],\n",
       "       [ 0.31357202,  0.4198027 ],\n",
       "       [ 0.3403133 ,  0.41163636],\n",
       "       [ 0.33392569,  0.42485291],\n",
       "       [ 0.33834346,  0.44583849],\n",
       "       [ 0.32502024,  0.42433862],\n",
       "       [ 0.33734157,  0.43136545],\n",
       "       [ 0.33172691,  0.40898388],\n",
       "       [ 0.33601028,  0.43245694],\n",
       "       [ 0.32685338,  0.41984171],\n",
       "       [ 0.32656377,  0.39672544],\n",
       "       [ 0.31903662,  0.4218722 ],\n",
       "       [ 0.33440618,  0.44512415],\n",
       "       [ 0.34702418,  0.44698435],\n",
       "       [ 0.33650282,  0.45495253],\n",
       "       [ 0.3311529 ,  0.43493275],\n",
       "       [ 0.33832769,  0.41765241],\n",
       "       [ 0.33226273,  0.41642755],\n",
       "       [ 0.3482933 ,  0.43248045],\n",
       "       [ 0.3244716 ,  0.42178363],\n",
       "       [ 0.33131281,  0.42391497],\n",
       "       [ 0.34120103,  0.43293779],\n",
       "       [ 0.34328123,  0.42773019],\n",
       "       [ 0.34459886,  0.45770366],\n",
       "       [ 0.32968826,  0.39098153],\n",
       "       [ 0.31765677,  0.40433744],\n",
       "       [ 0.32207281,  0.3876039 ],\n",
       "       [ 0.36178862,  0.44390768],\n",
       "       [ 0.36555658,  0.46335491],\n",
       "       [ 0.32673589,  0.41925578],\n",
       "       [ 0.33349398,  0.41218256],\n",
       "       [ 0.33605638,  0.43339889],\n",
       "       [ 0.34463185,  0.41717681],\n",
       "       [ 0.33684211,  0.42505278],\n",
       "       [ 0.33769303,  0.40702887],\n",
       "       [ 0.32797271,  0.42610261],\n",
       "       [ 0.33279743,  0.42158426],\n",
       "       [ 0.32890903,  0.45588765],\n",
       "       [ 0.33745727,  0.40531742],\n",
       "       [ 0.32959821,  0.41231044],\n",
       "       [ 0.33541167,  0.43641876],\n",
       "       [ 0.32450439,  0.41138445],\n",
       "       [ 0.35373204,  0.45798172],\n",
       "       [ 0.34248324,  0.43211418],\n",
       "       [ 0.33945244,  0.43452276],\n",
       "       [ 0.32453568,  0.39039855],\n",
       "       [ 0.3359375 ,  0.44837391],\n",
       "       [ 0.32076096,  0.41293072],\n",
       "       [ 0.35401403,  0.43735723],\n",
       "       [ 0.32162249,  0.41072701],\n",
       "       [ 0.33697749,  0.40566542],\n",
       "       [ 0.32188771,  0.38660166],\n",
       "       [ 0.33225858,  0.44750585],\n",
       "       [ 0.34039503,  0.4079064 ],\n",
       "       [ 0.33860911,  0.42413855],\n",
       "       [ 0.32024318,  0.39693295],\n",
       "       [ 0.34042216,  0.44389293],\n",
       "       [ 0.33990775,  0.42248692],\n",
       "       [ 0.35786006,  0.44728377],\n",
       "       [ 0.34163187,  0.42731515],\n",
       "       [ 0.33116143,  0.3994185 ],\n",
       "       [ 0.33338725,  0.42885411],\n",
       "       [ 0.32974032,  0.41281588],\n",
       "       [ 0.35357143,  0.46211592],\n",
       "       [ 0.31761624,  0.36855623],\n",
       "       [ 0.31807818,  0.38897749],\n",
       "       [ 0.35416996,  0.44291339],\n",
       "       [ 0.32548007,  0.43107498],\n",
       "       [ 0.32254297,  0.41478628],\n",
       "       [ 0.34989681,  0.43328602],\n",
       "       [ 0.3206344 ,  0.40786825],\n",
       "       [ 0.31986478,  0.40316276],\n",
       "       [ 0.33215092,  0.43782901],\n",
       "       [ 0.34040868,  0.42044238],\n",
       "       [ 0.32629527,  0.43262411],\n",
       "       [ 0.34518895,  0.40792291],\n",
       "       [ 0.32261749,  0.37297396],\n",
       "       [ 0.33295269,  0.39865601],\n",
       "       [ 0.32703679,  0.41486411],\n",
       "       [ 0.33574413,  0.41533201],\n",
       "       [ 0.32068342,  0.38228396],\n",
       "       [ 0.3170574 ,  0.38972701],\n",
       "       [ 0.34455917,  0.42902996],\n",
       "       [ 0.33074434,  0.41642599],\n",
       "       [ 0.32896032,  0.41149551],\n",
       "       [ 0.33927718,  0.41684626],\n",
       "       [ 0.3184892 ,  0.40527838],\n",
       "       [ 0.36175187,  0.47756184],\n",
       "       [ 0.35173177,  0.45390583],\n",
       "       [ 0.34285253,  0.43939949],\n",
       "       [ 0.33275481,  0.44030899],\n",
       "       [ 0.3318328 ,  0.41527234],\n",
       "       [ 0.35004791,  0.4414799 ],\n",
       "       [ 0.31958593,  0.44480637],\n",
       "       [ 0.31368664,  0.4019484 ],\n",
       "       [ 0.32839904,  0.3972063 ],\n",
       "       [ 0.33213056,  0.41500457],\n",
       "       [ 0.33160706,  0.40685381],\n",
       "       [ 0.34113498,  0.4261343 ],\n",
       "       [ 0.31756202,  0.39417796],\n",
       "       [ 0.31915606,  0.40011038],\n",
       "       [ 0.31827276,  0.38693004],\n",
       "       [ 0.33407608,  0.44693438],\n",
       "       [ 0.34027555,  0.41564968],\n",
       "       [ 0.3386218 ,  0.40548836],\n",
       "       [ 0.33509061,  0.39427838],\n",
       "       [ 0.33650129,  0.40615329],\n",
       "       [ 0.34586109,  0.41165951],\n",
       "       [ 0.34306569,  0.44053353],\n",
       "       [ 0.30934892,  0.38922265],\n",
       "       [ 0.32077326,  0.38064516],\n",
       "       [ 0.32442871,  0.41761006],\n",
       "       [ 0.34073002,  0.42151581],\n",
       "       [ 0.33174028,  0.41994894],\n",
       "       [ 0.33519375,  0.41520468],\n",
       "       [ 0.3215859 ,  0.37834882],\n",
       "       [ 0.33100763,  0.3993576 ],\n",
       "       [ 0.33285141,  0.40301526],\n",
       "       [ 0.34982666,  0.43596192],\n",
       "       [ 0.33907683,  0.45093872],\n",
       "       [ 0.31213873,  0.45423112],\n",
       "       [ 0.31561626,  0.38620814],\n",
       "       [ 0.33819055,  0.418811  ],\n",
       "       [ 0.32438663,  0.37793686],\n",
       "       [ 0.31126924,  0.39030612],\n",
       "       [ 0.29796536,  0.33943428],\n",
       "       [ 0.33847886,  0.43592042],\n",
       "       [ 0.33160538,  0.40184049],\n",
       "       [ 0.33471602,  0.42383161],\n",
       "       [ 0.30291786,  0.36206897],\n",
       "       [ 0.31962494,  0.40148766],\n",
       "       [ 0.30414201,  0.37337542],\n",
       "       [ 0.33199936,  0.41336678],\n",
       "       [ 0.33899402,  0.40087864],\n",
       "       [ 0.32101579,  0.40263967],\n",
       "       [ 0.31449753,  0.38261665],\n",
       "       [ 0.31818182,  0.39018088],\n",
       "       [ 0.32113419,  0.40834548],\n",
       "       [ 0.31740277,  0.37136548],\n",
       "       [ 0.33564181,  0.42477396],\n",
       "       [ 0.32155244,  0.37891633],\n",
       "       [ 0.32464995,  0.41567696],\n",
       "       [ 0.33975085,  0.433579  ],\n",
       "       [ 0.31729668,  0.39644219],\n",
       "       [ 0.31865073,  0.38767721],\n",
       "       [ 0.32866345,  0.41502116],\n",
       "       [ 0.30622808,  0.35994168],\n",
       "       [ 0.34338118,  0.44418268],\n",
       "       [ 0.32183156,  0.40231788],\n",
       "       [ 0.34877896,  0.46077058],\n",
       "       [ 0.31671792,  0.41284404],\n",
       "       [ 0.31604697,  0.41289167],\n",
       "       [ 0.33960141,  0.45997526],\n",
       "       [ 0.3125207 ,  0.40195901],\n",
       "       [ 0.31130521,  0.36867205],\n",
       "       [ 0.29238288,  0.34809076],\n",
       "       [ 0.32498341,  0.42500459],\n",
       "       [ 0.34085742,  0.42498192],\n",
       "       [ 0.32576   ,  0.40787598],\n",
       "       [ 0.30861723,  0.36764435],\n",
       "       [ 0.31427159,  0.40079294],\n",
       "       [ 0.31058862,  0.37370489],\n",
       "       [ 0.32260142,  0.39469439],\n",
       "       [ 0.30821018,  0.38712012],\n",
       "       [ 0.30858855,  0.38265025],\n",
       "       [ 0.33476874,  0.39071429],\n",
       "       [ 0.31759727,  0.38834423],\n",
       "       [ 0.32236189,  0.41320789],\n",
       "       [ 0.30303533,  0.36820999],\n",
       "       [ 0.32181999,  0.37509198],\n",
       "       [ 0.32919355,  0.40981241],\n",
       "       [ 0.30483951,  0.3485324 ],\n",
       "       [ 0.33453888,  0.4223886 ],\n",
       "       [ 0.31825658,  0.42189199],\n",
       "       [ 0.31651151,  0.39992903],\n",
       "       [ 0.3235675 ,  0.38135747],\n",
       "       [ 0.3248057 ,  0.39032722],\n",
       "       [ 0.33693548,  0.45311369],\n",
       "       [ 0.31127451,  0.41708633],\n",
       "       [ 0.31669138,  0.39422008],\n",
       "       [ 0.30924092,  0.40659741],\n",
       "       [ 0.31506849,  0.41488223],\n",
       "       [ 0.31026641,  0.40365479],\n",
       "       [ 0.33360311,  0.44597496],\n",
       "       [ 0.33163181,  0.43280347],\n",
       "       [ 0.29560166,  0.36894794],\n",
       "       [ 0.31529295,  0.41062625],\n",
       "       [ 0.33754195,  0.42102455],\n",
       "       [ 0.32498373,  0.43656649],\n",
       "       [ 0.30376344,  0.39504804],\n",
       "       [ 0.30160338,  0.37793384],\n",
       "       [ 0.30161128,  0.37137045],\n",
       "       [ 0.322152  ,  0.42760463],\n",
       "       [ 0.31982872,  0.38912442],\n",
       "       [ 0.31655738,  0.39953102],\n",
       "       [ 0.31568465,  0.38568807],\n",
       "       [ 0.30787191,  0.38201214],\n",
       "       [ 0.3273528 ,  0.39672544],\n",
       "       [ 0.31652521,  0.37366679],\n",
       "       [ 0.32791194,  0.41816184],\n",
       "       [ 0.31939164,  0.3799336 ],\n",
       "       [ 0.32972796,  0.43643536],\n",
       "       [ 0.34597231,  0.43435048],\n",
       "       [ 0.32670362,  0.40988106],\n",
       "       [ 0.31494633,  0.37862678],\n",
       "       [ 0.312409  ,  0.37994249],\n",
       "       [ 0.30217966,  0.37821319],\n",
       "       [ 0.34922883,  0.44611573],\n",
       "       [ 0.32904471,  0.40772842],\n",
       "       [ 0.31257152,  0.43096085],\n",
       "       [ 0.3069241 ,  0.37584878],\n",
       "       [ 0.31781806,  0.41069171],\n",
       "       [ 0.32659987,  0.41876472],\n",
       "       [ 0.32325203,  0.41199642],\n",
       "       [ 0.32894102,  0.41445956],\n",
       "       [ 0.30556459,  0.38952861],\n",
       "       [ 0.2988448 ,  0.37548103],\n",
       "       [ 0.33176049,  0.40147562],\n",
       "       [ 0.31324111,  0.3957346 ],\n",
       "       [ 0.32726394,  0.39079833],\n",
       "       [ 0.3105061 ,  0.39751553],\n",
       "       [ 0.30046404,  0.3921426 ],\n",
       "       [ 0.32125803,  0.40176438],\n",
       "       [ 0.31259408,  0.39753495],\n",
       "       [ 0.30565486,  0.36607303],\n",
       "       [ 0.30636226,  0.38379765],\n",
       "       [ 0.29263793,  0.3345568 ],\n",
       "       [ 0.32608696,  0.39628483],\n",
       "       [ 0.32319694,  0.39147287],\n",
       "       [ 0.307743  ,  0.37792278],\n",
       "       [ 0.32022288,  0.38130403],\n",
       "       [ 0.32265484,  0.41846758]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selec only 2 X variables\n",
    "X_new = SelectKBest(f_regression, k=2).fit_transform(X, y)\n",
    "X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f_regression determines that **OBP** and **SLG** are two most important predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = lm.LinearRegression()\n",
    "model2.fit(X_new, y)\n",
    "model2_y = model2.predict(X_new)\n",
    "\n",
    "print \"mean square error: \", mean_squared_error(y, model2_y)\n",
    "print \"variance or r-squared: \", explained_variance_score(y, model2_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use f_regression with k = 3 and develop a new regression model\n",
    "\n",
    "\n",
    "model3\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive Feature Selection (RFE): Another Feature Selection Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their rank:\n",
      "[(1, 'OBP'), (1, 'SLG'), (2, 'BA'), (3, 'HR'), (4, '3B'), (5, '2B'), (6, 'H'), (7, 'AB'), (8, 'SF'), (9, 'HBP'), (10, 'BB'), (11, 'W'), (12, 'RA'), (13, 'G'), (14, 'salary')]\n"
     ]
    }
   ],
   "source": [
    "lr = lm.LinearRegression()\n",
    "rfe = RFE(lr, n_features_to_select=2)\n",
    "rfe_y = rfe.fit(X,y)\n",
    "\n",
    "print \"Features sorted by their rank:\"\n",
    "print sorted(zip(map(lambda x: x, rfe.ranking_), X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'OBP'), (1, 'SLG'), (2, 'BA'), (3, 'HR'), (4, '3B'), (5, '2B'), (6, 'H'), (7, 'AB'), (8, 'SF'), (9, 'HBP'), (10, 'BB'), (11, 'W'), (12, 'RA'), (13, 'G'), (14, 'salary')]\n"
     ]
    }
   ],
   "source": [
    "# or you can do something like this: zip first and sort the data\n",
    "\n",
    "print sorted(zip(rfe.ranking_, X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: with fewer predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#First Model\n",
    "runs_reg_model1 = sm.ols(\"R~OBP+SLG+BA\",teams)\n",
    "runs_reg1 = runs_reg_model1.fit()\n",
    "#Second Model\n",
    "runs_reg_model2 = sm.ols(\"R~OBP+SLG\",teams)\n",
    "runs_reg2 = runs_reg_model2.fit()\n",
    "#Third Model\n",
    "runs_reg_model3 = sm.ols(\"R~BA\",teams)\n",
    "runs_reg3 = runs_reg_model3.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The first one will have as features OBP, SLG and BA. \n",
    "- The second model will have as features OBP and SLG. \n",
    "- The last one will have as feature BA only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print runs_reg1.summary()\n",
    "print runs_reg2.summary()\n",
    "print runs_reg3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The first model has an Adjusted R-squared of 0.918, with 95% confidence interval of BA between -283 and 468. This is counterintuitive, since we expect the BA value to be positive. This is due to a **multicollinearity** between the variables.\n",
    "\n",
    "- The second model has an Adjusted R-squared of 0.919, and the last model an Adjusted R-squared of 0.500.\n",
    "\n",
    "- Based on this analysis, we could confirm that the second model using **OBP** and **SLG** is the best model for predicting Run Scored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- http://adilmoujahid.com/posts/2014/07/baseball-analytics/ (reproduced from this page)\n",
    "- https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-ridge-lasso-regression-python/#four\n",
    "- http://www.python-course.eu/lambda.php (excellent resource for lamda and map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
