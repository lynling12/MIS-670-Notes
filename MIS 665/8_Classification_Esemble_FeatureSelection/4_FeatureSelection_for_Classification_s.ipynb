{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#import decisiontreeclassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#import logisticregression classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "#import knn classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#for validating your classification model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# feature selection\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Marital_Status  Gender  Weight_Category  Cholesterol  \\\n",
      "0   60               2       0                1          150   \n",
      "1   69               2       1                1          170   \n",
      "2   52               1       0                0          174   \n",
      "3   66               2       1                1          169   \n",
      "4   70               3       0                1          237   \n",
      "\n",
      "   Stress_Management  Trait_Anxiety 2nd_Heart_Attack  \n",
      "0                  1             50              Yes  \n",
      "1                  0             60              Yes  \n",
      "2                  1             35               No  \n",
      "3                  0             60              Yes  \n",
      "4                  0             65              Yes  \n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"data/heartattack_train.csv\")\n",
    "print df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling & ETL: Data cleaningg & transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mappling or replacing\n",
    "df = df.replace({'2nd_Heart_Attack': 'No'}, {'2nd_Heart_Attack': '0'})\n",
    "df = df.replace({'2nd_Heart_Attack': 'Yes'}, {'2nd_Heart_Attack': '1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#or you can do this to convert object to number\n",
    "df['2nd_Heart_Attack'] = df['2nd_Heart_Attack'].astype(int)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# another option: converting all object columns to numerical columns\n",
    "\n",
    "df['2nd_Heart_Attack'] = df['2nd_Heart_Attack'].convert_objects(convert_numeric=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['2nd_Heart_Attack']\n",
    "X = df.drop(['2nd_Heart_Attack'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building & Validation with \"Feature Selection\"\n",
    "> Feature Selection = the process of building a predictive model with few predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # 1. SelectKBest \n",
    "\n",
    "> Removes all but the k highest scoring features (where k is the number of X variables given by data analyst)\n",
    "\n",
    "> SelectKBest takes the results of chi-square for classification problem. chi-square tests if an individual X variable is independent of y variable. All X variables are tested. If found to be independent, the X variable is removed \n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html#sklearn.feature_selection.chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1 150  50]\n",
      " [  1 170  60]\n",
      " [  0 174  35]\n",
      " [  1 169  60]\n",
      " [  1 237  65]\n",
      " [  0 174  35]\n",
      " [  0 140  45]\n",
      " [  0 143  45]\n",
      " [  0 139  45]\n",
      " [  0 174  40]\n",
      " [  0 189  65]\n",
      " [  1 147  50]\n",
      " [  2 160  40]\n",
      " [  2 178  75]\n",
      " [  2 236  80]\n",
      " [  1 146  50]\n",
      " [  0 141  45]\n",
      " [  0 172  60]\n",
      " [  0 172  60]\n",
      " [  1 138  50]\n",
      " [  0 174  40]\n",
      " [  1 146  50]\n",
      " [  1 238  60]\n",
      " [  0 172  35]\n",
      " [  2 178  75]\n",
      " [  1 236  65]\n",
      " [  2 202  70]\n",
      " [  0 140  45]\n",
      " [  0 173  35]\n",
      " [  0 124  45]\n",
      " [  2 224  60]\n",
      " [  2 203  70]\n",
      " [  1 169  50]\n",
      " [  0 175  40]\n",
      " [  2 220  60]\n",
      " [  1 169  60]\n",
      " [  0 125  45]\n",
      " [  2 162  40]\n",
      " [  2 162  40]\n",
      " [  1 238  60]\n",
      " [  0 170  60]\n",
      " [  0 171  60]\n",
      " [  0 187  65]\n",
      " [  2 182  75]\n",
      " [  1 235  60]\n",
      " [  0 123  45]\n",
      " [  1 172  55]\n",
      " [  1 139  50]\n",
      " [  2 199  70]\n",
      " [  0 175  40]\n",
      " [  2 203  70]\n",
      " [  2 161  40]\n",
      " [  0 139  45]\n",
      " [  1 139  50]\n",
      " [  1 236  65]\n",
      " [  1 236  60]\n",
      " [  1 233  65]\n",
      " [  1 165  50]\n",
      " [  1 139  50]\n",
      " [  0 172  60]\n",
      " [  0 172  40]\n",
      " [  0 122  45]\n",
      " [  2 179  75]\n",
      " [  0 186  65]\n",
      " [  0 141  45]\n",
      " [  1 148  50]\n",
      " [  2 203  70]\n",
      " [  1 138  50]\n",
      " [  2 239  80]\n",
      " [  1 174  55]\n",
      " [  2 161  40]\n",
      " [  1 169  60]\n",
      " [  2 180  75]\n",
      " [  2 159  40]\n",
      " [  0 172  40]\n",
      " [  2 178  80]\n",
      " [  2 161  40]\n",
      " [  2 220  60]\n",
      " [  2 220  60]\n",
      " [  1 223  80]\n",
      " [  1 169  50]\n",
      " [  2 178  80]\n",
      " [  1 172  55]\n",
      " [  1 171  60]\n",
      " [  1 237  60]\n",
      " [  1 167  50]\n",
      " [  1 170  60]\n",
      " [  1 137  50]\n",
      " [  0 174  35]\n",
      " [  2 200  70]\n",
      " [  0 141  45]\n",
      " [  2 221  60]\n",
      " [  0 125  45]\n",
      " [  1 174  55]\n",
      " [  1 173  55]\n",
      " [  2 220  60]\n",
      " [  1 236  65]\n",
      " [  0 188  65]\n",
      " [  0 186  65]\n",
      " [  0 172  40]\n",
      " [  2 222  60]\n",
      " [  1 236  60]\n",
      " [  1 165  50]\n",
      " [  1 173  55]\n",
      " [  1 169  60]\n",
      " [  1 172  55]\n",
      " [  1 165  50]\n",
      " [  2 161  40]\n",
      " [  2 239  80]\n",
      " [  1 146  50]\n",
      " [  1 173  60]\n",
      " [  0 126  45]\n",
      " [  2 177  80]\n",
      " [  1 233  65]\n",
      " [  1 148  50]\n",
      " [  0 168  60]\n",
      " [  0 172  40]\n",
      " [  1 137  50]\n",
      " [  1 169  50]\n",
      " [  0 173  35]\n",
      " [  0 125  45]\n",
      " [  1 137  50]\n",
      " [  2 178  80]\n",
      " [  1 239  60]\n",
      " [  1 224  80]\n",
      " [  2 181  75]\n",
      " [  0 172  35]\n",
      " [  0 172  60]\n",
      " [  1 148  50]\n",
      " [  2 220  60]\n",
      " [  1 169  50]\n",
      " [  1 173  55]\n",
      " [  1 222  80]\n",
      " [  0 170  35]\n",
      " [  0 172  60]\n",
      " [  0 122  45]\n",
      " [  1 236  60]\n",
      " [  0 185  65]]\n"
     ]
    }
   ],
   "source": [
    "X_new = SelectKBest(chi2, k=3).fit_transform(X, y)\n",
    "print X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weight_Category, Cholesterol, and Trait_Anxiety** are selected as three best predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.928571428571\n",
      "--------------------------------------------------------\n",
      "[[18  1]\n",
      " [ 2 21]]\n",
      "--------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.95      0.92        19\n",
      "          1       0.95      0.91      0.93        23\n",
      "\n",
      "avg / total       0.93      0.93      0.93        42\n",
      "\n",
      "--------------------------------------------------------\n",
      "0.930205949657\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model by splitting into train (70%) and test sets (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=0)\n",
    "#model2 = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3,min_samples_leaf=5)\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "#Model evaluation\n",
    "print metrics.accuracy_score(y_test, dt.predict(X_test))\n",
    "print \"--------------------------------------------------------\"\n",
    "print metrics.confusion_matrix(y_test, dt.predict(X_test)) \n",
    "print \"--------------------------------------------------------\"\n",
    "print metrics.classification_report(y_test, dt.predict(X_test))\n",
    "print \"--------------------------------------------------------\"\n",
    "print metrics.roc_auc_score(y_test, dt.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the new decision tree\n",
    "X_new_df = pd.DataFrame(X_new)\n",
    "X_new_df = X_new_df.rename(columns={0: 'Weight_Category', 1: 'Cholesterol', 3: 'Trait_Anxiety'})\n",
    "tree.export_graphviz(dt, out_file='data/decisiontree.dot', feature_names=X_new_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the new decision tree (2nd option)\n",
    "from sklearn.externals.six import StringIO\n",
    "import pydotplus\n",
    "\n",
    "dot_data = StringIO() \n",
    "tree.export_graphviz(dt, out_file=dot_data, feature_names=X_new_df.columns,\n",
    "                     filled=True, rounded=True, special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "graph.write_pdf(\"data/dt.pdf\")\n",
    "# go to data folder and open the pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# develop logistic regression model with X_new (only three predictors or independent variables)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=0)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "#Model evaluation\n",
    "print metrics.accuracy_score(y_test, lr.predict(X_test))\n",
    "print metrics.confusion_matrix(y_test, lr.predict(X_test))\n",
    "print metrics.classification_report(y_test, lr.predict(X_test))\n",
    "print metrics.roc_auc_score(y_test, lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # 2. Recursive Feature Selection (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True False  True False  True False]\n",
      "[1 1 3 1 4 1 2]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 4)  #asking four best attributes\n",
    "rfe = rfe.fit(X, y)\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Weight_Category</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Stress_Management</th>\n",
       "      <th>Trait_Anxiety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Marital_Status  Gender  Weight_Category  Cholesterol  \\\n",
       "0   60               2       0                1          150   \n",
       "\n",
       "   Stress_Management  Trait_Anxiety  \n",
       "0                  1             50  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marital_Status</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gender</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weight_Category</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cholesterol</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stress_Management</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Trait_Anxiety</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature  importance\n",
       "0                Age           1\n",
       "1     Marital_Status           1\n",
       "2             Gender           3\n",
       "3    Weight_Category           1\n",
       "4        Cholesterol           4\n",
       "5  Stress_Management           1\n",
       "6      Trait_Anxiety           2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features sorted by their rank\n",
    "pd.DataFrame({'feature':X.columns, 'importance':rfe.ranking_})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# another method\n",
    "print \"Features sorted by their rank:\"\n",
    "print sorted(zip(map(lambda x: x, rfe.ranking_), X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Marital_Status  Weight_Category  Stress_Management\n",
      "0   60               2                1                  1\n",
      "1   69               2                1                  0\n",
      "2   52               1                0                  1\n",
      "3   66               2                1                  0\n",
      "4   70               3                1                  0\n"
     ]
    }
   ],
   "source": [
    "#here I select 4 most significant features only (including Age)\n",
    "X_logistic = df[['Age', 'Marital_Status', 'Weight_Category', 'Stress_Management']]\n",
    "print X_logistic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.904761904762\n",
      "[[16  3]\n",
      " [ 1 22]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.84      0.89        19\n",
      "          1       0.88      0.96      0.92        23\n",
      "\n",
      "avg / total       0.91      0.90      0.90        42\n",
      "\n",
      "0.899313501144\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_logistic, y, test_size=0.3, random_state=0)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "#Model evaluation\n",
    "print metrics.accuracy_score(y_test, lr.predict(X_test))\n",
    "print metrics.confusion_matrix(y_test, lr.predict(X_test))\n",
    "print metrics.classification_report(y_test, lr.predict(X_test))\n",
    "print metrics.roc_auc_score(y_test, lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # 3. Extra tree classifier: Tree-based feature selection\n",
    "> - http://scikit-learn.org/stable/modules/ensemble.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.09142621  0.22133476  0.0450213   0.28711802  0.1359188   0.0730589\n",
      "  0.14612201]\n"
     ]
    }
   ],
   "source": [
    "model_extra = ExtraTreesClassifier()\n",
    "model_extra.fit(X, y)\n",
    "model_extra.score(X, y)\n",
    "\n",
    "# display the relative importance of each attribute\n",
    "print(model_extra.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their rank:\n",
      "[(0.045, 'Gender'), (0.0731, 'Stress_Management'), (0.0914, 'Age'), (0.1359, 'Cholesterol'), (0.1461, 'Trait_Anxiety'), (0.2213, 'Marital_Status'), (0.2871, 'Weight_Category')]\n"
     ]
    }
   ],
   "source": [
    "print \"Features sorted by their rank:\"\n",
    "print sorted(zip(map(lambda x: round(x, 4), model_extra.feature_importances_), X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion & Storytelling\n",
    "\n",
    "- All three classification algorithms (decision tree, logistic regression, knn) work well for this dataset\n",
    "- Certain predictors are found important in predicting who is likely to experience 2nd heart attack\n",
    "> Weight_Category, Cholesterol, Martial_Status, Trait_Anxiety, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix : iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/iris.png\">\n",
    "<img src=\"images/iris_3.gif\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('data/iris.csv')\n",
    "iris.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.groupby('Name').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting X & y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a decision model \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the performance of this model & interpret the results\n",
    "# just get accuracy_score and confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize decision tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Embed the decision tree here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection: Building a predictive model with fewer predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 1. SelectBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SelectBest (k =2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What predictors are found to be important in predicting iris type?\n",
    "- PetalLength, PetalWidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then, declare X again with the two columns (not four). Name it as X_new (we want to use a different variable name not to overwrite X) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build decision tree model with two predictors (X_new)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Find out the performance of this model & interpret the results\n",
    "# just get accuracy_score and confusion_matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 2. Recursive Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build logisticRegression\n",
    "\n",
    "# selecting 3 highest ranking X variables\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the selection of the attributes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What predictors are found to be important in predicting iris type?\n",
    "- SepalWidth, PetalLength, PetalWidth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 3. ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build ExtraTreesClassifier\n",
    "\n",
    "\n",
    "\n",
    "# display the relative importance of each attribute\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
